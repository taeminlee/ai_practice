{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# colab을 이용한 기계학습 실습 pt.2\n",
    "\n",
    "🎯 학습 목표 : colab 환경에서 자연어 데이터를 활용하는 기계 학습 코드를 실행하고 결과를 확인할 수 있다.\n",
    "\n",
    "- 실습 재료\n",
    "\n",
    "| 항목 | 상세 |\n",
    "| ---- | ---- |\n",
    "| 🗂️ 데이터 | AI-HUB의 감성 대화 말뭉치 |\n",
    "| 🤖 기계 학습 알고리즘 | BERT |\n",
    "| 🏗️ 기계 학습 프레임워크 | transformers |\n",
    "| 🐍 프로그래밍 언어 | Python |\n",
    "| 👩‍💻 프로그래밍 환경 | Colab |\n",
    "\n",
    "\n",
    "- colab에서 코드 실행 방법은 다음 그림을 참조해주시기 바랍니다.\n",
    "    ![](https://i.imgur.com/0GoFr7q.png)\n",
    "\n",
    "# **주의** 본 실습은 GPU를 사용합니다. colab 런타임에 GPU 를 사용하도록 변경하여야 합니다!\n",
    "\n",
    "![](https://i.imgur.com/JrUzpgk.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## 1. Colab이란?\n",
    "\n",
    "- colab은 구글에서 제공하는 온라인 기계 학습 환경 입니다.\n",
    "\n",
    "![](https://post-phinf.pstatic.net/MjAxOTEwMTVfMTE4/MDAxNTcxMTA3ODE4NTcy.KmzXuRSS3HWe4qnBR7esUkTOCPELkbi6fD0khAX8i8kg.9KgltPv7JsznlhiQVmmCxwVFBqLUI03VZaAwFwxUfHkg.JPEG/29.JPG?type=w1200)\n",
    "*(그림 출처 : [네이버 블로그](https://post.naver.com/viewer/postView.nhn?volumeNo=26447765))*\n",
    "\n",
    "- 기계 학습 코드를 작성하고, 실행할 수 있습니다.\n",
    "  - 기계 학습 코드를 작성하기 위해서 필요한 것은 웹 브라우저뿐 입니다! 지금 여러분들이 보고 계시듯이 말이죠.\n",
    "  - 실행은 구글의 데이터 센터에서 실행됩니다. -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 필요 라이브러리 및 함수 추가\n",
    "\n",
    "실습에 앞서 아래의 코드 셀을 실행해주시기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이번 실습에 사용하는 데이터 및 함수를 다운로드 받습니다.\n",
    "## 참고 : 느낌표(!)로 시작하는 코드는 python이 아닌, linux 운영체제 명령어로 실행됩니다.\n",
    "!rm ai_practice -rf\n",
    "!git clone https://github.com/taeminlee/ai_practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 실습에서는 딥러닝을 이용하여 모델을 만듭니다.\n",
    "\n",
    "다음의 코드 셀을 실행하여 딥러닝 과정에서 사용하는 라이브러리를 설치합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 실습 목표 및 데이터 살펴보기\n",
    "\n",
    "이번 실습에서 사용되는 데이터는 [AI-HUB의 감성 대화 말뭉치](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=86) 입니다.\n",
    "\n",
    "해당 데이터를 이용하여 `사용자의 감정이 섞인 문장(text)`이 주어졌을 때, 어떠한 `감정`인지 판별(classifiaction)하는 모델을 만들어보도록 하겠습니다.\n",
    "\n",
    "![](https://i.imgur.com/s0Wa5WT.png)\n",
    "\n",
    "실습 데이터 집합에 대한 명세는 다음과 같습니다.\n",
    "\n",
    "- 데이터 개수 : 학습 데이터 51,360건, 검증 데이터 6,641건\n",
    "- 사용 항목\n",
    "  - 사람문장1\n",
    "    - 예) `일은 왜 해도 해도 끝이 없을까? 화가 난다.`\n",
    "  - 감정_대분류\n",
    "    - 예) `분노`\n",
    "    - 감정 클래스 : ('분노', '기쁨', '불안', '당황', '슬픔', '상처')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 불러옵니다.\n",
    "## 참고 : 해당 데이터 처리 코드는 https://github.com/taeminlee/ai_practice/data_util_2.py 에 기록되어 있습니다.\n",
    "from ai_practice.data_util_2 import dataset, sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터를 살펴보기 위해 이 코드 블록을 실행시켜 주십시오.\n",
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 데이터를 살펴보기 위해 이 코드 블록을 실행시켜 주십시오.\n",
    "dataset['test'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터 전처리\n",
    "\n",
    "자연어로 기술된 데이터를 딥러닝을 이용해 분석하기 위해서는 수치 값으로 변환이 필요합니다.\n",
    "\n",
    "이 중 가장 중요한 것은 [문장을 토큰으로 변환](https://wikidocs.net/21698)하는 과정입니다.\n",
    "\n",
    "다음의 코드 셀을 실행해서 토큰화 과정을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 과정에서 필요한 라이브러리를 준비합니다.\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "import torch\n",
    "\n",
    "# 토큰화\n",
    "tokenizer = AutoTokenizer.from_pretrained('beomi/kcbert-base')\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    tokenized_examples = tokenizer(str(examples[\"사람문장1\"]))\n",
    "    \n",
    "    return tokenized_examples\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function)\n",
    "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'labels', 'attention_mask', 'token_type_ids'])\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 결과를 확인하기 위해 코드 블록을 실행해 주시기 바랍니다.\n",
    "tokenized_dataset['train'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 모델 학습\n",
    "\n",
    "본 실습에서는 딥러닝 알고리즘 중 transfomer 계열의 BERT 네트워크를 기반으로 만들어진 KcBERT를 미세조정(fine tuning)하여 모델을 학습할 것 입니다.\n",
    "\n",
    "학습을 위해 [transformers](https://huggingface.co/docs/transformers/index) 라이브러리를 이용합니다.\n",
    "\n",
    "본 실습에서는 BERT구조로 모델을 학습할 것이므로, transformer 중 [BERT](https://huggingface.co/docs/transformers/model_doc/bert) 를 사용합니다.\n",
    "\n",
    "*(참고) 그 외 네트워크들은 [transformers 홈페이지의 summary of the models 페이지](https://huggingface.co/docs/transformers/model_summary) 에서 확인 가능합니다.*\n",
    "\n",
    "transformers 라이브러리에서 학습은 `Trainer` 클래스를 이용하여 수행하도록 구성되어 있습니다.\n",
    "\n",
    "다음의 코드는 KcBERT 기반 감성 클래스 분류기를 생성하고, 학습하는 과정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformers 라이브러리에서 BERT 분류기 클래스를 불러옵니다.\n",
    "from transformers import BertForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "\n",
    "\n",
    "# 감성 분류 BERT 모델 객체를 생성합니다.\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'beomi/kcbert-base', \n",
    "    num_labels=6, \n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "model.config.id2label = {i: label for i, label in zip(range(6), sentiments)}\n",
    "model.config.label2id = {label: i for i, label in zip(range(6), sentiments)}\n",
    "#\n",
    "model.to('cuda')\n",
    "\n",
    "def compute_metrics(x):\n",
    "    return {\n",
    "        'lrap': label_ranking_average_precision_score(x.label_ids, x.predictions),\n",
    "    }\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"model_output\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=2,\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='lrap',\n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=args, \n",
    "    train_dataset=tokenized_dataset[\"train\"], \n",
    "    eval_dataset=tokenized_dataset[\"test\"], \n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "# 결과 모델은 trainer 변수에 저장되어 있습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음의 코드는 학습된 모델에 임의의 문장을 넣어 테스트 하는 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "pipe = TextClassificationPipeline(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    device=0,\n",
    "    return_all_scores=True,\n",
    "    function_to_apply='sigmoid'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"야 이 개새끼들아!! 개 짖는 소리좀 안나게 하그라!\"  # @param\n",
    "for result in pipe(example_text)[0]:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이상으로 본 실습을 마치도록 하겠습니다.\n",
    "\n",
    "모두들 고생 많으셨습니다!\n",
    "\n",
    "![](https://img.favpng.com/10/1/7/kakaotalk-kakao-friends-emoticon-sticker-png-favpng-mZm2vp0mk2Ce9aTUnBjC4s4DZ.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('aihub')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a0c5c96cc83492e721e39f292a483d03caac9186ef6c7b30263cc9dd0a6903e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
